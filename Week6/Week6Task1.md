# Week 6 Task 1

## 临界区的概念及其必要性

临界区（critical section）指的是一种程序片段，在该片段中可以访问共享资源或共享数据，因此同一时刻只能允许一个执行线程进入此片段。如果多个线程或中断同时进入同一个临界区，就可能产生竞态条件（race condition），导致不可预测的结果。例如，两条线程同时对同一个全局计数器执行自增操作，可能因为交错执行顺序而造成最终结果比预期少。这种不确定性会带来数据不一致或系统异常，因此对临界区进行保护是有必须性的。 

临界区的必要性在于确保共享数据的原子性和一致性。只有一个线程能在某一时刻进入临界区，其他线程必须等待其退出后才能进入，从而避免竞态。为此，程序员需要识别出可能产生竞态的代码区域（即临界区），并在进出这些区域时使用同步机制（如锁）进行保护。在单处理器系统上，不使用抢占的情况下，一个线程在内核中的执行不会被另一线程中途打断，因此不会有两个线程同时运行相同的临界区代码；但在多处理器系统或支持内核抢占的情况下，如果没有同步保护，多线程可以并发执行，临界区就很容易发生竞态问题。

---

##  内核抢占模型对并发的影响

Linux 内核提供了多种抢占模型，决定了内核代码执行时是否允许被中断和切换，从而影响并发性能和系统响应延迟。主要的模式有以下几种：

- **无抢占内核（Non-Preemptive Kernel，配置选项 ```CONFIG_PREEMPT_NONE```）：** 这种模式下，当进程在内核态运行时，不会被另一可运行进程抢占。内核线程将一直运行直到主动放弃 CPU（例如执行阻塞操作）或返回用户态为止。在单核环境下，这意味着一次只会有一个线程执行内核代码，内核在同一时间不发生线程切换，因此几乎不会出现内核数据结构上的竞态（除非有中断或异常并发访问）。这种模型实现相对简单，不需要过多锁来保护内核数据，但缺点是在执行长时间的内核任务时会导致高延迟，降低系统响应性。
  
- **可抢占内核（Preemptive Kernel，配置选项 ```CONFIG_PREEMPT```）：** 可抢占内核允许进程在内核态运行时被抢占，当有更高优先级的可运行进程出现或在某些内核安全点（如中断返回前或明确的调度点）时，调度器可以中断当前内核线程，切换到其他线程执行。Linux 从 2.6 内核开始引入了内核抢占选项，以改善内核延迟问题。在开启抢占的内核中，并发性提高：即使在单处理器上，一个线程在内核中运行也可能被切换出去，从而另一个线程进入内核。这带来了更复杂的同步需求，内核必须通过锁等机制精心设计，确保共享数据不会因为抢占而产生竞态条件。相对于无抢占模式，可抢占内核提高了系统的响应性和实时性能，因为不会出现某个低优先级线程长时间占用内核不放的情况。但对于对称多处理（SMP）系统来说，即使无抢占模式，不同CPU上也可并行执行内核代码，因此在SMP上仍然需要锁保护共享数据；而可抢占模式在SMP下并发更多，设计更为复杂。
  
- **实时抢占内核（Fully Preemptible Kernel, ```PREEMPT_RT```）：** 实时抢占（通过 ```PREEMPT_RT``` 补丁，在 Linux 主线中作为 ```CONFIG_PREEMPT_RT ```模式）使得内核几乎完全可抢占，目标是满足实时系统对确定性时延的要求。在 ```PREEMPT_RT``` 模式下，内核尽可能将非抢占区域缩到最小：几乎所有内核代码都可以被抢占（除了极少数关键部分）。为此，```PREEMPT_RT``` 对内核同步机制作了调整，普通的自旋锁（```spinlock_t```）不再是真正“忙等”的自旋，而是被替换为可以睡眠的锁实现，只有 ```raw_spinlock_t``` 仍保持禁止抢占的原语。另外，所有硬中断处理程序都被线程化（变成内核线程形式），只有极少数对时延要求极高的硬件中断会以非线程方式运行。这样一来，在内核中即便原本由于禁用中断或持有锁而不能被抢占的区域，在 ```RT``` 内核中也变得可调度，让高优先级的实时任务可以迅速获得 CPU 使用权。```PREEMPT_RT``` 模式极大降低了内核的最坏情况调度延迟，使 Linux 能用于严苛的实时场景。需要注意，在 ```PREEMPT_RT ```内核中，如果仍然出现内核无法及时被抢占的长临界区，一般被视为内核的 bug 需要修复。

---

## Linux 内核提供的同步机制及死锁的成因与避免

为保护临界区，Linux 内核提供了多种同步机制来实现互斥和协调。其中主要包括自旋锁、互斥锁和信号量等。这些机制各有适用场景：

- **自旋锁（spinlock）：** 一种忙等待锁，只有一个持有者。当线程尝试获取自旋锁而锁已被他人持有时，线程不会睡眠，而是在 CPU 上不断循环等待锁释放（“自旋”）。由于不涉及上下文切换，自旋锁开销很小且效率高，适合于临界区很短或者不能睡眠的场景（如中断处理上下文或其他原子上下文）。但是，如果临界区较长，自旋会浪费 CPU 时间，因此不适合持有时间较长的锁。

- **互斥锁（mutex）：** 仅允许单一持有者的锁，特征是会引起睡眠。当线程获取互斥锁失败时，线程会被挂起（进入睡眠等待队列），让出 CPU 给其他任务运行，而不是一直占用 CPU 等待。当锁可用时，睡眠的线程会被唤醒并获得锁。互斥锁适用于可以睡眠的上下文（进程上下文），特别是临界区执行时间较长的情况，用互斥锁可以避免长时间占用 CPU。需要注意 Linux 内核中的互斥锁（```struct mutex```）不可递归（同一线程不允许连续两次锁定自身已持有的同一把锁，否则会自陷死锁）。


- **信号量（semaphore）：** 信号量在内核中是一种通用的计数器型锁机制，它可以用来控制对资源的访问数。经典的“信号量”允许多个线程在不超过给定计数的情况下同时进入临界区（计数值通常代表资源数量）。Linux 内核中的信号量实现（```struct semaphore```，提供 ```down()/up()``` 操作）与互斥锁类似，也是在获取不到时睡眠等待，但它的计数允许它被用于允许并发访问固定次数的场景，例如同时允许 N 个线程并发访问。同样地，内核还有读写信号量（```struct rw_semaphore```），用于实现多读单写的同步机制，即允许多个读者或单个写者并发。不过在现代内核中，很多场景下二值信号量（计数为1的信号量）已被 mutex 所替代，因为 mutex 接口更简单且有调试支持。

**死锁的成因：** 死锁是指两个或多个执行单元（线程或进程）因互相等待对方而陷入永久阻塞的一种情形。在内核同步中，最常见的死锁情形是循环等待：例如线程A持有锁X，等待获取锁Y；同时线程B已持有锁Y，正等待锁X释放，这样双方互相等待对方释放资源，结果谁也等不到，系统逻辑陷入僵局。这种两锁死锁常被称为ABBA死锁（因为等待顺序A->B和B->A形成环路）。更一般地，死锁发生需要以下四个条件：互斥（资源独占不可共享）、占有且等待（已占有一个资源再请求新资源时不释放已有资源）、不可抢占（资源不能被强行夺走，只能自愿释放）以及循环等待（存在环形的资源依赖链）。当所有这些条件都满足时，就会发生死锁。

**死锁的避免策略：**
- **固定的锁获取顺序：** 对可能需要同时持有多个锁的情况，预先定义一个全局一致的加锁顺序，并严格按照该顺序获取锁。例如如果所有代码约定先锁定资源 A 再锁定资源 B，那么就不会出现一个线程先锁B再锁A而另一线程先锁A再锁B的循环等待情形。确保无环依赖可从根本上防止“ABBA”死锁发生。

- **避免嵌套过深的锁定：** 尽量减少在同一代码路径上同时持有多个锁的数量，锁越多，发生死锁的组合可能性越大。保持锁定逻辑的简洁，有助于避免复杂的交叉依赖。

- **禁止递归锁定：** Linux 内核的自旋锁和 mutex 都不支持同一线程重复获取同一把锁（非递归锁），这是有意的设计，因为允许递归锁虽然避免了同一线程的自死锁，但容易诱使程序员编写混乱的锁定逻辑。因此应当设计代码逻辑避免需要递归锁的情况。如果确实需要递归性质，可以考虑重新设计逻辑或使用其他同步手段。

- **使用内核死锁检测工具：** Linux 内核提供了锁依赖验证机制（Lockdep），只要在内核配置中启用并在运行时触发，Lockdep会监测锁的获取顺序是否可能产生死锁，并在发现潜在问题时输出警告。在开发调试内核时，开启这些调试选项可以提早发现并纠正死锁隐患。

---


## Linux 内核内存管理的三大关键数据结构

- ```page```：Page 代表物理内存中的一个“页框”（page frame），是内存管理的最小基本单位。一页通常大小为 4KB，在内核中使用 ```struct page``` 数据结构来表示每个物理页。通过 ```struct page```，内核可以跟踪页面的状态信息，例如页面是否空闲、引用计数、是否存在于缓存等。内核采用伙伴分配算法（Buddy Allocator）来管理物理页：将连续的空闲页框合并成更大块以满足高阶内存分配需求，在释放内存时又根据需要拆分或合并页块。这种机制保证了内存分配和回收的效率，同时减少内存碎片。

- ```Zone```（区域）：Zone 是对物理内存地址空间中特定范围的一种抽象，它位于 Page 之上、Node 之下的层级。每个内存节点（Node）会按照地址范围和用途将其包含的物理内存划分为若干 Zone，每个 Zone 包含一定范围的页框，并通常具有特定用途或访问限制。常见的内存区域类型包括：
    - ***ZONE_DMA：*** DMA 区域，供某些无法访问高地址的旧式设备进行 DMA 操作所使用的低位内存。典型情况下 x86 架构下该区域大小为前 16MB。
    - ***ZONE_DMA32：*** 仅在部分 64 位系统上存在，用于32位设备进行 DMA 的内存区域（物理地址在 4GB 以下）。
    - ***ZONE_NORMAL：*** 常规内存区域，指可以被内核直接永久映射并高效访问的物理内存范围（例如 x86 上 16MB–896MB 的区域，在 64 位系统中如果总内存小于4GB则该区域可能为空）。
    - ***ZONE_HIGHMEM：*** 高端内存区域，仅存在于32位系统中，指超出直接映射范围的高地址内存。内核无法直接永久映射该区域的内存，需要通过临时映射才能访问（在64位系统由于地址空间充裕，一般不需要此区域）。
    - ***ZONE_MOVABLE：*** 可移动内存区域，与普通内存类似但其中大部分页可以在物理内存中移动。该区域用于内存热插拔或减少内存碎片等场景，其内容可迁移，以便在需要时腾出连续物理内存。
  
    每个 Zone 由内核的 ```struct zone``` 结构体描述，它是页面分配器（页帧分配器）的核心数据结构。Zone 描述了该区域的起始地址、大小以及维护着该区域内空闲内存块的链表和水位标记等信息（例如空闲内存的低水位和高水位，用于触发内存回收机制）。划分 Zone 的目的在于让内核分配内存时能够根据内存的特性选择合适的区域，例如通常优先使用高端内存或可移动内存进行分配，保留低地址的 DMA 内存以满足设备需求。如果一个 Zone 无法满足分配请求，内核会按顺序在更低的 Zone 寻找可用页，从而逐级回退确保分配成功。

- ```Node```：Node 是物理内存按拓扑划分的最高层级单位，主要用于描述NUMA架构下的内存分布。在NUMA（非一致内存访问）系统中，每个 Node 通常对应一块与特定 CPU 或处理器组具有本地亲和性的物理内存区域（内存银行）。简单来说，一个多处理器系统中每个CPU可能有自己的本地内存节点；而在UMA（一致内存访问）架构下，整个系统只有一个内存节点 Node0（相当于将UMA视作只有单节点的NUMA）。 
  
    Node 在内核中由 ```struct pglist_data```（类型别名为 ```pg_data_t```）数据结构表示，该结构体包含了该节点的所有 Zone 列表（```node_zones```）以及该节点管理的所有物理页的描述数组（```node_mem_map```）等信息。换句话说，Node 结构中保存着属于该节点的各区域和页的全局统计和管理数据。例如，在 ```pg_data_t``` 中有一个指针指向该节点的所有 ```struct page``` 构成的数组，用于描述整个位于该 Node 上的物理内存页。 
    
    划分 Node 的意义在于反映硬件的内存拓扑结构，方便内核针对NUMA系统进行优化。当内核需要分配内存时，会优先尝试从当前CPU所在的本地内存节点获取页帧（节点局部分配策略），这样可以利用CPU对本地内存的快速访问提高性能。如果本地节点内存不足，分配器才会考虑其他节点的内存。通过 Node 的划分，Linux内核即使在NUMA架构下也能高效地管理内存并确保尽量使用本地内存；对于UMA系统，则可以将其视为所有内存都隶属于单一节点来简化处理。

---

## 伙伴系统

伙伴系统（Buddy System）是 Linux 内核中用于管理物理内存页分配和释放的基础算法。其核心思想是将空闲内存划分成大小为 2 的幂（power-of-two）的块，以便快速找到适合大小的块满足内存分配请求，同时在释放时能够合并相邻的空闲块减少碎片。

原理：伙伴算法维护了一系列按照块大小分类的空闲内存链表。例如，order=0 表示基本块大小（通常是1页=4KB），order=1 表示2页块（8KB），order=2 表示4页块（16KB），以此类推。最大支持的 order 由系统内存大小决定（Linux 通常定义 ```MAX_ORDER```，例如 10 表示最大块大小 2^10 * 4KB = 4MB）。初始时，伙伴系统将整个空闲内存视作尽可能大的 2^n 块（可能不是整个内存，因为内存大小不一定是2的幂），其余部分用更小块补齐。 

当有内存分配请求（通常是以页为单位，如需要分配 8 个连续页）时，伙伴算法会选取最小的能够满足请求的空闲块。实现中，它会在对应大小的空闲链表中查找可用块：如果正好有同尺寸的空闲块，则直接分配；如果没有，则向上寻找更大的块，将其 **拆分（split）** 成两个“伙伴”块，每个大小减半（比如将一个 order=3 的块拆成两个 order=2 的块）。如果所需大小仍然没得到，则继续拆分直到得到所需大小的块为止。这样，每次拆分产生的一对块互称为“伙伴”，因为它们来自同一个更大的块。 

当释放内存时，内核会检查所释放的块的伙伴块是否也空闲：如果是，那么这对伙伴块会合并（coalesce）成一个更大的块（order + 1），然后再看看这个新块的伙伴是否也空闲，如是则继续合并，依次类推，直到不能再合并为止。通过这种 “拆分-合并” 机制，伙伴系统能够在相对高效的时间复杂度内处理不同大小内存的申请，并且尽量将相邻空闲内存块重新合并成更大块，减少外部碎片。 

***用途：*** Linux 内核的页面分配器（```__alloc_pages()``` 等接口背后）就是基于伙伴系统实现的。当内核需要分配一页或多页连续物理内存时（如分配2页、4页的高阶内存），使用伙伴算法可以快速找到合适的内存块。比如 ```kmalloc()``` 请求较大内存时，底层也会调用页面分配器（伙伴系统）来提供物理页面。当伙伴系统无法提供所需连续页时，说明内存碎片化严重或者空闲不足，此时可能需要内存回收或采用不同策略。 

由于伙伴系统管理的是页框级别的内存，它与前面提到的 ```struct page``` 紧密相关：每个物理页的 ```struct page``` 中有一些位用于表示该页是否被分配、所属块 order 等信息。当一块连续的内存由伙伴系统分配出去时，相应的那些页的状态会从空闲变为已分配，并从空闲链表摘除；释放时则反之。

---

## Slab 分配器及其着色机制

slab 分配器是构建在页分配器（伙伴系统）之上的一层内存分配机制，主要用于分配内核对象（如数据结构）并提高内存分配/释放效率，减少碎片和 CPU 缓存失效。其思想是借鉴对象缓存（object cache）的理念：针对内核中经常分配和释放的对象类型（比如进程控制块 ```task_struct```、```inode``` 结构等），维护一个缓存池，里面直接保存着已分配好的一批对象实例。当需要新对象时，从缓存池中取出一个已分配但未使用的对象；当释放对象时，将其回收到缓存池而非交还底层系统。这样做有几个好处：
- ***降低分配开销：*** 重复使用对象避免了每次都调用伙伴系统分配页、初始化内存的开销。对象在缓存池（slab）中是预先分配好的，取用时几乎是 O(1) 操作。
  
- ***减少内存碎片：*** slab 将相同大小的对象紧凑地存储在连续的页框中，一个页往往容纳多个对象。这些页块周转使用，使得释放对象时并不会把内存还给伙伴系统，从而避免对象大小不一导致的外部碎片。当某个 slab 中所有对象都空闲时，slab 分配器才会把整页归还给伙伴系统，因此碎片基本以页为单位管理。

- ***提高缓存局部性：*** slab 分配器倾向于重用最近释放的对象（本地 CPU 的对象缓存，称为 per-CPU slab），并且对象往往会保留以前使用时的初始化状态。当再次使用时，可以避免重新初始化，且数据可能还留在 CPU 缓存中，从而加速访问。此外，slab 支持 NUMA 感知和 CPU本地缓存，减少跨节点/跨CPU竞争。

slab 分配器将每种类型的对象建立一个缓存（cache），每个缓存包含若干个 slab，每个 slab 由一页或几页物理内存组成，能容纳若干个该类型对象。slab 按使用情况分为三类：满的、部分用的、空的。当需要分配对象时，从部分用的 slab 中拿；如果没有部分 slab，则看有没有空 slab，有的话从空的拿，没有则向伙伴系统申请新页建立一个 slab。释放对象时，如果该 slab 上的对象全部变空闲且系统内存紧张，则 slab 可能被回收。

***着色（cache coloring）机制：*** slab 分配器一个重要的优化是缓存着色。问题由来是这样的：在传统情况下，相同类型的对象往往在每个 slab 中具有相同的内存偏移。例如，某种对象大小是 256 字节，那么在每个4KB页的 slab 中可能排布16个对象，它们在页内的偏移分别是0, 256, 512等。如果不同 slab 上的对象被同时使用，它们在物理内存中的地址可能不同，但在各自页内的偏移可能相同。这就意味着它们很可能映射到CPU缓存的相同缓存行上（因为许多CPU采用物理地址的低位来索引缓存行）。结果，两个不同 slab 上的对象如果频繁被交替访问，可能会在缓存中互相冲刷：同一个缓存行被来回装载不同对象的数据，造成性能下降。

为缓解这个问题，slab 分配器引入了“颜色”。Slab 着色指的是为每个新分配的 slab 设置一个起始偏移，使得它上面的对象相对于页的起点有一个不同的偏移量。比如，第一个 slab 对齐页开头放对象，第二个 slab 也许从页开头偏移64字节处开始放第一个对象，第三个偏移128字节，如此等等（偏移量的单位通常是缓存行大小）。这样一来，不同 slab 上相同序号的对象在物理地址中不会对齐到相同缓存行，提高了缓存行的利用率，避免多个对象竞争同一缓存行。简单说，缓存着色通过在内存布局上“打乱”对象在页内的位置，减少了CPU缓存的冲突失效。Linux 内核正是通过在 ```kmem_cache``` 中设置 ```cachep->colour``` 和 ```colour_off``` 等参数，实现对每个 slab 起始地址的微调，确保存放对象的位置多样化。正如《Linux Kernel Development》所总结的：“存储的对象可以着色以防止多个对象映射到同一个缓存行”。

---

## 上层应用调用 malloc() 申请内存时，从用户空间到内核空间发生了什么

当应用程序在用户空间调用 C 库的 ```malloc()``` 函数申请内存时，实际发生的过程包括用户态的分配管理和内核态的内存提供两个阶段。大致过程如下：

1. ***用户态分配器处理：*** ```malloc()```并非系统调用，而是用户空间的库函数（例如 GNU C 库的 ```malloc``` 实现）。C 库维护了用户进程的堆区（heap）以及内部的空闲内存链表（freelist）等结构。当调用 ```malloc(size)``` 时，库首先检查在它已管理的堆内存中是否有足够的空闲块可供分配。如果有，它会从空闲链表中拆出一块内存返回给应用，而不需要进入内核。这意味着许多小的 ```malloc/free``` 调用在用户态就完成了管理，内核对此毫不知情。

2. ***向内核请求内存：*** 如果用户态的堆内存不足以满足此次 ```malloc```请求（比如堆空间已耗尽，需要扩展，或请求特别大的块以至于glibc策略直接使用mmap），那么 C 库的 ```malloc``` 实现会通过系统调用向内核请求更多内存。常用的两种方式是：
   - ***```brk()```系统调用：*** 这会调整进程数据段（堆）的末尾位置（```brk```值）。```sbrk()/brk()``` 可以将堆空间向上增长一定大小，使进程的堆段变大，从而提供更多连续虚拟地址给 ```malloc``` 使用。内核处理 ```brk``` 时，会检查是否可以将进程的堆 VMA（通常起始于 ```end_data```，结束于当前 ```brk```）延伸，如果可以则更新 ```mm_struct``` 中堆区域的大小，并确保为新扩展的区域分配物理页框（或者标记将在缺页时分配）供后续使用。

   - ***```mmap()``` 系统调用：*** glibc 的 ```malloc``` 对于请求特别大的内存块，通常不是扩展主堆，而是直接调用 ```mmap(NULL, size, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, ...)``` 向内核申请匿名内存映射。内核接到 ```mmap``` 请求后，会在进程地址空间中找一块空闲虚拟地址区域来建立新的 VMA（长度为请求的 size，属性为匿名可读写），并返回此区域的首地址给用户空间。如果新区域和相邻的虚拟区可以合并且属性相同，内核可能会进行合并优化。但对应用而言，这只是得到一个新的可用内存起始地址。
  
    无论是 ```brk``` 还是 ```mmap```，最终效果都是进程的虚拟地址空间扩大了（或者新区域建立了），提供了用户程序可用的地址返回给 ```malloc```。内核在这一步中修改了进程的 ```mm_struct```（例如更新了 ```brk``` 值或增加了一项 VMA）以及相应的页表条目。需要注意，```mmap``` 返回的新区域在第一次使用之前可能并没有真正分配物理内存——它是按需分配的：当程序首次访问该区域时触发缺页异常，内核再实际分配物理页并映射。这种延迟分配提高了效率。

3. ***物理内存分配：*** 对于通过 ```brk``` 或 ```mmap``` 拿到的新虚拟内存区域，在需要时内核会为其分配物理内存页。这通常发生在页错误（Page Fault）处理期间：当应用对新区域的某地址执行读/写且该页尚未映射物理内存时，内核的页错误处理器会从伙伴系统分配一个空闲页，初始化（清零）后，将它映射到相应的虚拟页（更新进程页表），并增加该物理页对应的 ```struct page``` 引用计数。这种方式下，内核确保所请求的虚拟地址有实际的物理页支撑。在某些情况下（例如 ```mmap``` 使用了 ```MAP_POPULATE``` 标志），内核也可能在系统调用阶段就预先分配并映射所有页。

4. ***用户态完成分配：*** 内核将新获得的内存区首地址返回给 C 库的 ```malloc``` 实现。C 库随后可能将这块内存纳入它自己的管理：如果是来自 ```brk``` 扩展的堆，则这块内存会被并入用户态分配器的空闲列表，然后从中划出一部分返回给调用者；如果是通过 ```mmap``` 单独获取的大块，则直接将这一大块返回给调用者（并在内部记录，以便 ```free``` 时用 ```munmap``` 归还给内核）。

5. ***释放内存：*** 当应用调用 ```free(ptr)``` 时，C 库通常会将该内存标记为空闲并加入自身的空闲链表，而并不立即通知内核回收，以便后续的 ```malloc``` 可以重用。这意味着进程从内核申请来的内存往往不会归还，除非符合特定条件（比如大块 ```mmap``` 分配的内存在 ```free``` 时glibc会直接用 ```munmap``` 释放给内核）。因此，通常一个进程向内核申请的堆内存只增不减，直到进程结束时操作系统回收整个进程地址空间。